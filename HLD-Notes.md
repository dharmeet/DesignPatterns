# HLD Notes

## Topic wise

| Topic | Description | Use-case |
| ----- | ---------- | --------- |
| Consistent Hashing | multiple hash functions for servers and single hash function for user_id | Used in case of sharding is done by user_id |
|  Load Balancer | Listener (entry point) - Routing (decision making process based on rules and algorithms) - Target Group (collection of servers that actually process the request), Reverse Proxy, Security, Performance, Resilience  | |
| In-Browser Caching | DNS and static information like image, videos and JS files | Mostly used in all the websites |
| CDN (Content Delivery Network) | Store the data, distribute it to all the regions and provide different CDN links to access data in a particular region | Video Streaming like Hoststar, Youtube etc. |
| Local Caching | Caching done on the app server | Tests input and output files for a problem on Scaler, Hackerrank etc. Metadata DB stores the last updated time and compares if we need to get the file from file storage or local cache. | 
| Global Caching | System like Redis, Memcache. Used mostly for caching something that is queried often, storing derived information which might be expensive to compute on DB. | Contest ranklist - compute the ranklist periodically (eg. 1 min) and update it in Redis, this way there would be only one cache miss every minute. |
| Cache with TTL | Entries in the cache will be valid for only a period, after that if you need it you fetch it again. | Weather Data, Caching currency exchange rates |
| Write through cache | Writing in cache and DB, returning success if both are successful. Writes are slower but reads are much faster. | Read-heavy system, E-commerce inventory update |
| Write back cache | First write in cache, then asynchronously sync with DB. Very high throughput and very low latency. | Social media feeds/counters (eg. likes, count), Video streaming watch history |
| Write around cache | Writes are done directly in the DB, can use TTL to keep cache in sync with the DB | Logging system, Infrequently accessed archival data |
| CAP Theorem | Distributed system can only provide two of three properties simultaneously Consistency, Availability and Partition tolerance. Consistency - return success only if both have written, Availability - mark the inactive node as active only when it has synced the data with others, Network Partitioning - one has to choose between availability (A) and consistency (C), if there is no network partitioning we have to choose between extremely low Latency or high Consistency. | (a) In banking system, consistency is important, we want immediate consistency but in reality ATM transactions use eventual consistency. (b) In FB newsfeed like system, availability is more important than consistency. (c) For Quora, availability is more important. (d) For Facebook messenger, consistency is very important. |
| Master slave | All writes first come to master, reads can go to any machine, whenever master dies a new election of the master will take place based on election algorithms. | |
| Master slave highly available not eventually consistent | Master takes the write, if successful return success. Try to sync with slaves. | Log system, like Splunk, throughput is high we need to process the logs even if we lose some logs, it's ok. |
| Master slave highly available and eventually consistent | Master takes the write and if one slave writes success is returned. | FB newsfeed and storing posts, we don't want post be lost, they could be delayed but eventually sync up. |
| Master slave highly consistent | Master and all slaves take the writes, if all have written then only return success. | Banking system. |
| SQL | Normalization and ACID transactions are the advantages of SQL. On the other hand, fixed schema might not fit every use case, also if we need to do DB sharding then it nullifies the advantages of sharding. | |
| Points to note while choosing sharding key | 1. Load should be evenly distributed. 2. Most frequent operations should be performed efficiently. 3. Minimum machines should be updated when most frequent operations are performed. 4. Minimize redundancy as much as possible.  | Banking system, user_id is better sharding key then city_id. Uber-like system, use case is to search for nearby drivers, CityId would be a good sharding key compared to driverId. Slack (Groups-heavy system) GroupId is the good sharding key. IRCTC Sharding key - primary problem is to avoid double-booked tickets, load balancing during tatkal booking. TrainId is a good sharding key, load gets distributed among all machines, tomorrow there would be lot of trains, within a train it knows which user is allocated a particular berth. |


## Case Studies

| S. No. | Problem | Approach |
| ----- | ---------- | --------- |
| 1 | Submit problem on Hackerrank, scaler (etc.) the input and output file is stored in File Storage which can take 2 seconds to fetch | Reading the file from Hard Disk takes 40 ms and reading a record from DB takes 50 ms. Store the file metadata in DB, with problem_id, input_filepath, input_file_updated_at, input_file_created_at and keep the filename as (problem_id)_(updated_at)_input.txt, now when the submission comes check the updated_at in the DB, if the file is present in local cache we are good, else fetch it from the filesystem. |
| 2 | How facebook computes its newsfeed (posts made by friends of the user) ? |  Posts made by user would be very less as compared to number of active users (80-20-1 rule), 1% will do posts, 80% reading, 20% interact. MAU - 1 Billion, DAU - 500 million, posts writing 1% - 5 million, lets say each person writes 4 posts daily, so we have 20 million posts every day. Each post is ~ 300 bytes, so space required for posts generated in a day 20 Mn * 300 = 6 GB. Assume only need to show posts made in last 30 days, so total space needed is 180 GB for 30 days. Hence, posts can be stored in a separate DB and retrieving becomes easier from the derived data. So recent posts, can be stored on multiple machines and separate DB for user data, so to give the recent posts we first get the friend_ids of the user, then select recent posts made by the user's friend SELECT * FROM all_posts WHERE user_id IN friend_ids LIMIT x OFFSET y. Here we are caching the posts in the HDD, not in RAM, but still this is much faster than getting the data from an actual storage system. |  